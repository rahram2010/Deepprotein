{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets start by importing a bunch of stuff\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading and separating data\n",
    "\n",
    "#explictily setting the types and names\n",
    "names_data = ['entry','entry_name','protein_name','gene_name','organism','length','sequence',\n",
    "              'gene_ontology','status','organism_id','keywords']\n",
    "\n",
    "dtypes_data = {'entry':'str','entry_name':'str','protein_name':'str','gene_name':'str',\n",
    "               'organism':'str','length':'int','sequence':'str','gene_ontology':'str','status':'str',\n",
    "               'organism_id':'int','keywords':'str'}\n",
    "\n",
    "\n",
    "protein_data = pd.read_csv('uniprot-filtered-reviewed_yes.tab',sep='\\t',names = names_data,dtype=dtypes_data,skiprows=1)\n",
    "\n",
    "\n",
    "#Seeing what the data looks like\n",
    "protein_data.shape\n",
    "\n",
    "#randomly shuffling dataset \n",
    "\n",
    "protein_data = protein_data.sample(frac=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(556604, 11)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ignoring protein's with ambigous amino acid codes \n",
    "\n",
    "protein_data = protein_data[~protein_data.sequence.str.contains('B')]\n",
    "protein_data = protein_data[~protein_data.sequence.str.contains('O')]\n",
    "protein_data = protein_data[~protein_data.sequence.str.contains('J')]\n",
    "protein_data = protein_data[~protein_data.sequence.str.contains('U')]\n",
    "protein_data = protein_data[~protein_data.sequence.str.contains('X')]\n",
    "protein_data = protein_data[~protein_data.sequence.str.contains('Z')]\n",
    "\n",
    "protein_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#encoding the sequence to a one-hot encoding scheme \n",
    "labels = np.array(['A','C','D','E','F','G','H','I','K','L','M','N','P','Q','R','S','T','V','W','Y'])\n",
    "\n",
    "\n",
    "#label encoding - integer encoding \n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(labels)\n",
    "\n",
    "# onehot encoder\n",
    "onehot_encoder = OneHotEncoder(sparse=False, categories = [range(20)], dtype=int)\n",
    "\n",
    "\n",
    "def one_hot_encoder(my_string):\n",
    "    \"\"\"function to turn sequence onehot encoded\"\"\"\n",
    "    my_array = np.array(list(my_string)) # converts string into array\n",
    "    integer_encoded = label_encoder.transform(my_array)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "    return onehot_encoded\n",
    "\n",
    "#testing custom onehot_encoder\n",
    "test_sequence = protein_data.sequence[0]\n",
    "string_to_array(test_sequence)\n",
    "one_hot_encoder(test_sequence)\n",
    "\n",
    "#applying onehot_encoder to entire dataframe(takes 6 minutes)\n",
    "protein_data['sequence_encoded'] = protein_data['sequence'].apply(one_hot_encoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(556511, 12)\n",
      "5900\n"
     ]
    }
   ],
   "source": [
    "#print(protein_data.head(1))\n",
    "\n",
    "#filtering the length of the sequences, dropping sequences greater than 6000\n",
    "index_data = protein_data.loc[protein_data.length > 6000].index\n",
    "protein_data = protein_data.drop(index_data)\n",
    "\n",
    "\n",
    "def make_all_same_length(my_array):\n",
    "    \"\"\"function to make all the sequence encoded arrays into the same length\"\"\"\n",
    "    max_length = protein_data.length.max() # 5900\n",
    "    \n",
    "#Dividing into 80 percent training and 20 percent test\n",
    "train, test = np.split(protein_data, [int(.8*len(protein_data))])\n",
    "\n",
    "#removing GO labels and keywords from the test dataset\n",
    "test = test.drop(columns=['gene_ontology','keywords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
